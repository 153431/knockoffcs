# Output: SVR_predicted_test_labels_for_{method}.npy, SVR model for {method}.npy
# RFR_predicted_test_labels_for_{method}.npy, RFR model for {method}.npy
# RD_predicted_test_labels_for_{method}.npy, RD model for {method}.npy
# SGD_predicted_test_labels_for_{method}.npy, SGD model for {method}.npy
# MLPR_predicted_test_labels_for_{method}.npy, MLPR model for {method}.npy


import numpy as np
import pandas as pd
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Ridge, LinearRegression, BayesianRidge, Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.neural_network import MLPRegressor
import xgboost

def _SVR(train_X, train_labels, test_X, test_labels, method):
    svr = SVR()
    svr.fit(train_X, train_labels)
    predicted_test_labels = svr.predict(test_X)
    mse = mean_squared_error(test_labels, predicted_test_labels)
    #print("SVR mse:", mse)
    #filename = f"SVR_predicted_test_labels_for_{method}.npy"
    #np.save(filename, test_labels, allow_pickle=True)
    return mse

def _RFR(train_X, train_labels, test_X, test_labels, method):
    rfr = RandomForestRegressor(n_estimators=100, random_state=42)
    rfr.fit(train_X, train_labels)
    predicted_test_labels = rfr.predict(test_X)
    mse = mean_squared_error(test_labels, predicted_test_labels)
    #print("RFR mse:", mse)
    #filename = f"RFR_predicted_test_labels_for_{method}.npy"
    #np.save(filename, test_labels, allow_pickle=True)
    return mse

def _ridge(train_X, train_labels, test_X, test_labels, method):
    rd = Ridge()
    rd.fit(train_X, train_labels)
    predicted_test_labels = rd.predict(test_X)
    mse = mean_squared_error(test_labels, predicted_test_labels)
    #print("RD mse:", mse)
    #filename = f"RD_predicted_test_labels_for_{method}.npy"
    #np.save(filename, test_labels, allow_pickle=True)
    return mse

def _XGB(train_X, train_labels, test_X, test_labels, method):
    xgb = xgboost.XGBRegressor(objective='reg:squarederror', eval_metric='rmse')
    xgb.fit(train_X, train_labels)
    predicted_test_labels = xgb.predict(test_X)
    mse = mean_squared_error(test_labels, predicted_test_labels)
    #print("XGBoost mse:", mse)
    #filename = f"XGBoost_predicted_test_labels_for_{method}.npy"
    #np.save(filename, test_labels, allow_pickle=True)
    return mse
def _linear(train_X, train_labels, test_X, test_labels, method):
    lr = LinearRegression()
    lr.fit(train_X, train_labels)
    predicted_test_labels = lr.predict(test_X)
    mse = mean_squared_error(test_labels, predicted_test_labels)
    #print("Linear mse:", mse)
    #filename = f"Linear_predicted_test_labels_for_{method}.npy"
    #np.save(filename, test_labels, allow_pickle=True)
    return mse

def _bayesian_ridge(train_X, train_labels, test_X, test_labels, method):
    br = BayesianRidge()
    br.fit(train_X, train_labels)
    predicted_test_labels = br.predict(test_X)
    mse = mean_squared_error(test_labels, predicted_test_labels)
    #print("BayesianRidge mse:", mse)
    #filename = f"BayesianRidge_predicted_test_labels_for_{method}.npy"
    #np.save(filename, test_labels, allow_pickle=True)
    return mse

def _knn(train_X, train_labels, test_X, test_labels, method):
    knn = KNeighborsRegressor(n_neighbors=5)
    knn.fit(train_X, train_labels)
    predicted_test_labels = knn.predict(test_X)
    mse = mean_squared_error(test_labels, predicted_test_labels)
    #print("KNN mse:", mse)
    #filename = f"KNN_predicted_test_labels_for_{method}.npy"
    #np.save(filename, test_labels, allow_pickle=True)
    return mse

def _lasso(train_X, train_labels, test_X, test_labels, method):
    lasso = Lasso(alpha=1.0)
    lasso.fit(train_X, train_labels)
    predicted_test_labels = lasso.predict(test_X)
    mse = mean_squared_error(test_labels, predicted_test_labels)
    #print("Lasso mse:", mse)
    #filename = f"Lasso_predicted_test_labels_for_{method}.npy"
    #np.save(filename, test_labels, allow_pickle=True)
    return mse
def assessment(train_X, train_labels, test_X, test_labels, method_name, high_dim, knockoff_selection_ratio):
    if method_name == "knockoffCS":
        method = f"{method_name}-{high_dim}-{knockoff_selection_ratio}"
    else:
        method = f"{method_name}-{high_dim}"
    svr = _SVR(train_X, train_labels, test_X, test_labels, method)
    rfr = _RFR(train_X, train_labels, test_X, test_labels, method)
    ridge = _ridge(train_X, train_labels, test_X, test_labels, method)
    linear = _linear(train_X, train_labels, test_X, test_labels, method)
    bayesian_ridge = _bayesian_ridge(train_X, train_labels, test_X, test_labels, method)
    knn = _knn(train_X, train_labels, test_X, test_labels, method)
    lasso = _lasso(train_X, train_labels, test_X, test_labels, method)
    XGB = _XGB(train_X, train_labels, test_X, test_labels, method)
    mse_score = {
        'method': method,
        'SVR': svr,
        'RF': rfr,
        'Ridge': ridge,
        'Linear': linear,
        'BayesianRidge': bayesian_ridge,
        'KNN': knn,
        'Lasso': lasso,
        'XGB': XGB
    }
    return mse_score


def XGBoostModel(train_X, train_labels, test_X, test_labels, method):
    xgb = xgboost.XGBRegressor(objective='reg:squarederror', eval_metric='rmse')
    xgb.fit(train_X, train_labels)
    predicted_test_labels = xgb.predict(test_X)
    mse = mean_squared_error(test_labels, predicted_test_labels)
    print(f"{method} XGBoost mse:", mse)
    filename = f"XGBoost_predicted_test_labels_for_{method}.npy"
    np.save(filename, test_labels, allow_pickle=True)


variables = np.load("Original Dataset_variables.npy", allow_pickle=True).T
labels = np.load("Original Dataset_labels.npy", allow_pickle=True)

total_size = variables.shape[0]
high_dim = variables.shape[1]
knockoff_selection_ratio = 0.01

train_size = 2500  # 想要的训练集大小
# 生成所有索引
all_indices = np.arange(total_size)
# 打乱索引
np.random.shuffle(all_indices)
# 划分训练集和测试集索引
train_indices = all_indices[:train_size]
test_indices = all_indices[train_size:]

variables_train = variables[train_indices]
variables_test = variables[test_indices]
labels_train = labels[train_indices]
labels_test = labels[test_indices]

original_mse = assessment(variables_train, labels_train, variables_test, labels_test, 'original', high_dim, knockoff_selection_ratio)

import sys
from datetime import datetime

original_stdout = sys.stdout  # 备份原标准输出

with open("output - original.txt", "w", encoding="utf-8") as file:
    sys.stdout = file  # 重定向到文件
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(timestamp,'\n')
    print(original_mse)
    sys.stdout = original_stdout  # 恢复标准输出

print("这行会在控制台打印")